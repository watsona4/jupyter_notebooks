{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import tempfile\n",
    "import traceback\n",
    "from contextlib import contextmanager\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import browser_cookie3\n",
    "import google_auth_httplib2\n",
    "import imagehash\n",
    "import progressbar\n",
    "import requests\n",
    "from google.auth.exceptions import RefreshError\n",
    "from google.auth.transport.requests import Request\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import build_http\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from pprint import pprint\n",
    "from requests.cookies import MockRequest\n",
    "\n",
    "SCOPES = [\"https://www.googleapis.com/auth/photoslibrary.readonly\"]\n",
    "\n",
    "LIST = []\n",
    "TOKEN = None\n",
    "\n",
    "LOAD_LIST = False\n",
    "LOAD_DUPL = False\n",
    "\n",
    "COOKIES = browser_cookie3.chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrlError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def tempinput(data):\n",
    "    temp = tempfile.NamedTemporaryFile(delete=False)\n",
    "    temp.write(data)\n",
    "    temp.close()\n",
    "    try:\n",
    "        yield temp.name\n",
    "    finally:\n",
    "        os.unlink(temp.name)\n",
    "\n",
    "\n",
    "def get_image(photo):\n",
    "    response = requests.get(photo[\"baseUrl\"])\n",
    "    return response.content\n",
    "\n",
    "\n",
    "def hash_diff(a, b):\n",
    "    return abs(a - b) <= 500_000_000_000  # 200\n",
    "\n",
    "\n",
    "class Hash:\n",
    "    def __init__(self, hash):\n",
    "        self.hash = hash\n",
    "    def __hash__(self):\n",
    "        return 1  # self.hash\n",
    "    def __eq__(self, other):\n",
    "        return hash_diff(other.hash, self.hash)\n",
    "    def __str__(self):\n",
    "        return str(self.hash)\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    \n",
    "def get_hash(image):\n",
    "    with tempinput(image) as fp:\n",
    "        return Hash(int(\"0x\" + str(imagehash.phash(Image.open(fp))), base=16))\n",
    "\n",
    "    \n",
    "def get_50(iterable):\n",
    "    result = []\n",
    "    for item in iterable:\n",
    "        result.append(item)\n",
    "        if len(result) == 50:\n",
    "            yield result\n",
    "            result.clear()\n",
    "    yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"photos_list_error.pkl\"):\n",
    "    with open(\"photos_list_error.pkl\", \"rb\") as fp:\n",
    "        TOKEN = pickle.load(fp)\n",
    "        LIST = pickle.load(fp)\n",
    "\n",
    "creds = None\n",
    "\n",
    "if not os.path.exists(\"credentials.pkl\"):\n",
    "    # Set up Google Photos API credentials\n",
    "    flow = InstalledAppFlow.from_client_secrets_file(\"credentials4.json\", SCOPES)\n",
    "    creds = flow.run_local_server(port=0)\n",
    "    with open(\"credentials.pkl\", \"wb\") as fp:\n",
    "        pickle.dump(creds, fp)\n",
    "else:\n",
    "    with open(\"credentials.pkl\", \"rb\") as fp:\n",
    "        creds = pickle.load(fp)\n",
    "\n",
    "# Set up the Google Photos API client\n",
    "service = build(\"photoslibrary\", \"v1\", credentials=creds, static_discovery=False)\n",
    "http = google_auth_httplib2.AuthorizedHttp(creds, http=build_http())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download image metadata and binary image file\n",
    "\n",
    "if LOAD_LIST:\n",
    "    with open(\"photos_list.pkl\", \"rb\") as infile:\n",
    "        LIST = pickle.load(infile)\n",
    "else:\n",
    "    bar = progressbar.ProgressBar(max_value=22706)\n",
    "\n",
    "    while True:\n",
    "        if not creds.valid:\n",
    "            creds.refresh(Request())\n",
    "\n",
    "        try:\n",
    "            results = service.mediaItems().list(pageSize=100, pageToken=TOKEN).execute()\n",
    "        except HttpError as err:\n",
    "            if err.status_code == 429:\n",
    "                if os.path.exists(\"photos_list_error.pkl\"):\n",
    "                    os.remove(\"photos_list_error.pkl\")\n",
    "                with open(\"photos_list_error.pkl\", \"wb\") as fp:\n",
    "                    pickle.dump(TOKEN, fp)\n",
    "                    pickle.dump(LIST, fp)\n",
    "            raise\n",
    "\n",
    "        if \"nextPageToken\" not in results:\n",
    "            break\n",
    "\n",
    "        TOKEN = results[\"nextPageToken\"]\n",
    "\n",
    "        items = results.get(\"mediaItems\", [])\n",
    "        for item in items:\n",
    "            if \"image\" not in item[\"mimeType\"] or \"gif\" in item[\"mimeType\"]:\n",
    "                continue\n",
    "            if \"image\" not in item:\n",
    "                item[\"image\"] = get_image(item)\n",
    "            LIST.append(item)\n",
    "            bar.update(len(LIST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (22706 of 22706) |##################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "squares = []\n",
    "for item in progressbar.ProgressBar()(LIST):\n",
    "    metadata = item[\"mediaMetadata\"]\n",
    "    if (\n",
    "        \"width\" in metadata\n",
    "        and \"height\" in metadata\n",
    "        and metadata[\"width\"] == metadata[\"height\"]\n",
    "    ):\n",
    "        squares.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22706 photos, 155 square (0.7%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(LIST)} photos, {len(squares)} square ({len(squares)/len(LIST)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"photos_squares.out\", \"w\") as fp:\n",
    "    for i, item in enumerate(squares):\n",
    "        fp.write(item[\"productUrl\"])\n",
    "        if (i + 1) % 100 == 0:\n",
    "            fp.write(\"\\n\")\n",
    "        else:\n",
    "            fp.write(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (22706 of 22706) |##################| Elapsed Time: 0:05:10 Time:  0:05:10\n"
     ]
    }
   ],
   "source": [
    "# Get hashes\n",
    "for item in progressbar.ProgressBar()(LIST):\n",
    "    try:\n",
    "        item[\"hash\"] = get_hash(item[\"image\"])\n",
    "    except (KeyError, OSError):\n",
    "        pass\n",
    "    except UnidentifiedImageError:\n",
    "        if not creds.valid:\n",
    "            creds.refresh(Request())\n",
    "        try:\n",
    "            result = service.mediaItems().get(mediaItemId=item[\"id\"]).execute()\n",
    "            item[\"image\"] = get_image(result)\n",
    "            item[\"hash\"] = get_hash(item[\"image\"])\n",
    "        except HttpError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_LIST:\n",
    "    with open(\"photos_list.pkl\", \"wb\") as fp:\n",
    "        pickle.dump(LIST, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (22706 of 22706) |##################| Elapsed Time: 0:03:56 Time:  0:03:56\n"
     ]
    }
   ],
   "source": [
    "# Find duplicate hashes\n",
    "if LOAD_DUPL:\n",
    "    with open(\"photos_duplicates.pkl\", \"rb\") as infile:\n",
    "        DUPL = pickle.load(infile)\n",
    "else:\n",
    "    hashes = {}\n",
    "    DUPL = {}\n",
    "    for item in progressbar.ProgressBar()(LIST):\n",
    "        try:\n",
    "            hash = item[\"hash\"]\n",
    "        except KeyError:\n",
    "            pass\n",
    "        if hash in hashes:\n",
    "            if item[\"id\"] != hashes[hash][\"id\"]:\n",
    "                DUPL.setdefault(hash, [hashes[hash]]).append(item)\n",
    "        else:\n",
    "            hashes[hash] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (472 of 472) |######################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "# Sort duplicates\n",
    "for key, val in progressbar.ProgressBar()(DUPL.items()):\n",
    "    val.sort(\n",
    "        key=lambda x: (\n",
    "            -int(x[\"mediaMetadata\"][\"width\"] if \"width\" in x[\"mediaMetadata\"] else 0),\n",
    "            datetime.fromisoformat(x[\"mediaMetadata\"][\"creationTime\"].strip(\"Z\")),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597 photos before prune\n"
     ]
    }
   ],
   "source": [
    "num_dupl = sum(len(val[1:]) for val in DUPL.values())\n",
    "print(f\"{num_dupl} photos before prune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (472 of 472) |######################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "# Remove real duplicate locations from DUPL\n",
    "for key, val in progressbar.ProgressBar()(DUPL.items()):\n",
    "    for item in val[1:]:\n",
    "        if item[\"id\"] == val[0][\"id\"]:\n",
    "            val.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530 photos after prune\n"
     ]
    }
   ],
   "source": [
    "num_dupl = sum(len(val[1:]) for val in DUPL.values())\n",
    "print(f\"{num_dupl} photos after prune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_DUPL:\n",
    "    with open(\"photos_duplicates.pkl\", \"wb\") as fp:\n",
    "        pickle.dump(DUPL, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22706 photos, 530 duplicates (2.3%)\n"
     ]
    }
   ],
   "source": [
    "num_dupl = sum(len(val[1:]) for val in DUPL.values())\n",
    "print(f\"{len(LIST)} photos, {num_dupl} duplicates ({num_dupl/len(LIST)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (472 of 472) |######################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    }
   ],
   "source": [
    "# Make duplicate photo directories\n",
    "\n",
    "shutil.rmtree(\"photos\", ignore_errors=True)\n",
    "\n",
    "os.mkdir(\"photos\")\n",
    "\n",
    "for key, val in progressbar.ProgressBar()(DUPL.items()):\n",
    "    keydir = os.path.join(\"photos\", str(key))\n",
    "    os.mkdir(keydir)\n",
    "    orig = True\n",
    "    for item in val:\n",
    "        if \"image\" not in item:\n",
    "            continue\n",
    "        mime, ext = item[\"mimeType\"].split(\"/\")\n",
    "        if mime != \"image\":\n",
    "            continue\n",
    "        filename = f\"{item['id']}.{ext}\"\n",
    "        if orig:\n",
    "            filename = f\"!original_{filename}\"\n",
    "            orig = False\n",
    "        with open(os.path.join(keydir, filename), \"wb\") as fp:\n",
    "            fp.write(item[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (472 of 472) |######################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "with open(\"photos_duplicates.out\", \"w\") as fp:\n",
    "    for key, val in progressbar.ProgressBar()(DUPL.items()):\n",
    "        print(f\"Hash: {key}\", file=fp)\n",
    "        for item in val:\n",
    "            print(f\"    {item['productUrl']}\", file=fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of items to be deleted\n",
    "batch = dict(\n",
    "    sorted(\n",
    "        DUPL.items(),\n",
    "        key=lambda x: datetime.fromisoformat(\n",
    "            x[1][0][\"mediaMetadata\"][\"creationTime\"].strip(\"Z\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "batch = [item[\"productUrl\"] for val in batch.values() for item in val[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(\"photos_tabs.out\", \"w\") as fp:\n",
    "    for i, url in enumerate(batch):\n",
    "        fp.write(url)\n",
    "        if (i + 1) % 100 == 0:\n",
    "            fp.write(\"\\n\")\n",
    "        else:\n",
    "            fp.write(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (9588 of 9588) |####################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "# Create list of dates to be changed\n",
    "dates = []\n",
    "for key, val in progressbar.ProgressBar()(DUPL.items()):\n",
    "    url = val[0][\"productUrl\"]\n",
    "    orig_date = datetime.fromisoformat(\n",
    "        val[0][\"mediaMetadata\"][\"creationTime\"].strip(\"Z\")\n",
    "    )\n",
    "    min_date = min(\n",
    "        [\n",
    "            datetime.fromisoformat(entry[\"mediaMetadata\"][\"creationTime\"].strip(\"Z\"))\n",
    "            for entry in val\n",
    "        ]\n",
    "    )\n",
    "    if orig_date - min_date > timedelta(days=1):\n",
    "        dates.append([min_date, url])\n",
    "\n",
    "dates.sort(key=lambda x: x[0])\n",
    "\n",
    "for i, date in enumerate(dates):\n",
    "    dates[i][0] = date[0].strftime(\"%Y %m %d %I:%M %p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (513 of 513) |######################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "with open(\"photos_dates.out\", \"w\") as fp:\n",
    "    for date, url in progressbar.ProgressBar()(dates):\n",
    "        print(date, url, file=fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP HERE UNTIL DELETION COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5953 of 5953) |####################| Elapsed Time: 0:00:36 ETA:  00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305 squares are still there!\n"
     ]
    }
   ],
   "source": [
    "# Detect any existing squares\n",
    "bar = progressbar.ProgressBar(max_value=len(squares))\n",
    "\n",
    "existing = []\n",
    "for items in get_50(squares):\n",
    "    ids = list(set([item[\"id\"] for item in items]))\n",
    "    results = service.mediaItems().batchGet(mediaItemIds=ids).execute()\n",
    "    existing += [item[\"mediaItem\"][\"productUrl\"] for item in results[\"mediaItemResults\"] if \"mediaItem\" in item]\n",
    "    bar.update(bar.value + len(items))\n",
    "\n",
    "print(f\"{len(existing)} squares are still there!\")\n",
    "\n",
    "with open(\"photos_missed_squares.out\", \"w\") as fp:\n",
    "    for i, url in enumerate(existing):\n",
    "        fp.write(url)\n",
    "        if (i + 1) % 100 == 0:\n",
    "            fp.write(\"\\n\")\n",
    "        else:\n",
    "            fp.write(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (26358 of 26358) |##################| Elapsed Time: 0:00:00 ETA:  00:00:00\n",
      "  5% (1350 of 26358) |                   | Elapsed Time: 0:00:11 ETA:   0:03:47"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m items \u001b[38;5;129;01min\u001b[39;00m get_50(duplicates):\n\u001b[0;32m      8\u001b[0m     ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m items))\n\u001b[1;32m----> 9\u001b[0m     results \u001b[38;5;241m=\u001b[39m service\u001b[38;5;241m.\u001b[39mmediaItems()\u001b[38;5;241m.\u001b[39mbatchGet(mediaItemIds\u001b[38;5;241m=\u001b[39mids)\u001b[38;5;241m.\u001b[39mexecute()\n\u001b[0;32m     10\u001b[0m     existing \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmediaItem\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproductUrl\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmediaItemResults\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmediaItem\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m item]\n\u001b[0;32m     11\u001b[0m     bar\u001b[38;5;241m.\u001b[39mupdate(bar\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(items))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[0;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\googleapiclient\\http.py:923\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody))\n\u001b[0;32m    922\u001b[0m \u001b[38;5;66;03m# Handle retries for server-side errors.\u001b[39;00m\n\u001b[1;32m--> 923\u001b[0m resp, content \u001b[38;5;241m=\u001b[39m _retry_request(\n\u001b[0;32m    924\u001b[0m     http,\n\u001b[0;32m    925\u001b[0m     num_retries,\n\u001b[0;32m    926\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sleep,\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rand,\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muri),\n\u001b[0;32m    930\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod),\n\u001b[0;32m    931\u001b[0m     body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    932\u001b[0m     headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    933\u001b[0m )\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_callbacks:\n\u001b[0;32m    936\u001b[0m     callback(resp)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\googleapiclient\\http.py:191\u001b[0m, in \u001b[0;36m_retry_request\u001b[1;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m     resp, content \u001b[38;5;241m=\u001b[39m http\u001b[38;5;241m.\u001b[39mrequest(uri, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Retry on SSL errors and socket timeout errors.\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _ssl_SSLError \u001b[38;5;28;01mas\u001b[39;00m ssl_error:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\google_auth_httplib2.py:218\u001b[0m, in \u001b[0;36mAuthorizedHttp.request\u001b[1;34m(self, uri, method, body, headers, redirections, connection_type, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m     body_stream_position \u001b[38;5;241m=\u001b[39m body\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    217\u001b[0m \u001b[38;5;66;03m# Make the request.\u001b[39;00m\n\u001b[1;32m--> 218\u001b[0m response, content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    219\u001b[0m     uri,\n\u001b[0;32m    220\u001b[0m     method,\n\u001b[0;32m    221\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    222\u001b[0m     headers\u001b[38;5;241m=\u001b[39mrequest_headers,\n\u001b[0;32m    223\u001b[0m     redirections\u001b[38;5;241m=\u001b[39mredirections,\n\u001b[0;32m    224\u001b[0m     connection_type\u001b[38;5;241m=\u001b[39mconnection_type,\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    226\u001b[0m )\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# If the response indicated that the credentials needed to be\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# refreshed, then refresh the credentials and re-attempt the\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# request.\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# A stored token may expire between the time it is retrieved and\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# the time the request is made, so we may need to try twice.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    234\u001b[0m     response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refresh_status_codes\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m _credential_refresh_attempt \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_refresh_attempts\n\u001b[0;32m    236\u001b[0m ):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httplib2\\__init__.py:1724\u001b[0m, in \u001b[0;36mHttp.request\u001b[1;34m(self, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[0;32m   1722\u001b[0m             content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1723\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1724\u001b[0m             (response, content) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1725\u001b[0m                 conn, authority, uri, request_uri, method, body, headers, redirections, cachekey,\n\u001b[0;32m   1726\u001b[0m             )\n\u001b[0;32m   1727\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1728\u001b[0m     is_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(e, socket\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httplib2\\__init__.py:1444\u001b[0m, in \u001b[0;36mHttp._request\u001b[1;34m(self, conn, host, absolute_uri, request_uri, method, body, headers, redirections, cachekey)\u001b[0m\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auth:\n\u001b[0;32m   1442\u001b[0m     auth\u001b[38;5;241m.\u001b[39mrequest(method, request_uri, headers, body)\n\u001b[1;32m-> 1444\u001b[0m (response, content) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conn_request(conn, request_uri, method, body, headers)\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auth:\n\u001b[0;32m   1447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m auth\u001b[38;5;241m.\u001b[39mresponse(response, body):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\httplib2\\__init__.py:1396\u001b[0m, in \u001b[0;36mHttp._conn_request\u001b[1;34m(self, conn, request_uri, method, body, headers)\u001b[0m\n\u001b[0;32m   1394\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1395\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1396\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m   1397\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mBadStatusLine, http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mResponseNotReady):\n\u001b[0;32m   1398\u001b[0m     \u001b[38;5;66;03m# If we get a BadStatusLine on the first try then that means\u001b[39;00m\n\u001b[0;32m   1399\u001b[0m     \u001b[38;5;66;03m# the connection just went stale, so retry regardless of the\u001b[39;00m\n\u001b[0;32m   1400\u001b[0m     \u001b[38;5;66;03m# number of RETRIES set.\u001b[39;00m\n\u001b[0;32m   1401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m seen_bad_status_line \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1276\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1277\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Detect any existing duplicates\n",
    "duplicates = [item for val in DUPL.values() for item in val[1:]]\n",
    "\n",
    "bar = progressbar.ProgressBar(max_value=len(duplicates))\n",
    "\n",
    "existing = []\n",
    "for items in get_50(duplicates):\n",
    "    ids = list(set(item[\"id\"] for item in items))\n",
    "    results = service.mediaItems().batchGet(mediaItemIds=ids).execute()\n",
    "    existing += [item[\"mediaItem\"][\"productUrl\"] for item in results[\"mediaItemResults\"] if \"mediaItem\" in item]\n",
    "    bar.update(bar.value + len(items))\n",
    "\n",
    "print(f\"{len(existing)} duplicates are still there!\")\n",
    "\n",
    "with open(\"photos_missed.out\", \"w\") as fp:\n",
    "    for i, url in enumerate(existing):\n",
    "        fp.write(url)\n",
    "        if (i + 1) % 100 == 0:\n",
    "            fp.write(\"\\n\")\n",
    "        else:\n",
    "            fp.write(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (9588 of 9588) |####################| Elapsed Time: 0:01:21 ETA:  00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1613 originals are missing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (1613 of 1613) |####################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    }
   ],
   "source": [
    "# Detect any missing originals\n",
    "originals = [val[0] for val in DUPL.values()]\n",
    "\n",
    "bar = progressbar.ProgressBar(max_value=len(originals))\n",
    "\n",
    "missing = []\n",
    "for items in get_50(originals):\n",
    "    ids = list(set(item[\"id\"] for item in items))\n",
    "    results = service.mediaItems().batchGet(mediaItemIds=ids).execute()\n",
    "    missing += [items[i] for i, result in enumerate(results[\"mediaItemResults\"]) if \"status\" in result]\n",
    "    bar.update(bar.value + len(items))\n",
    "\n",
    "print(f\"{len(missing)} originals are missing!\")\n",
    "\n",
    "shutil.rmtree(\"missing\", ignore_errors=True)\n",
    "\n",
    "os.mkdir(\"missing\")\n",
    "\n",
    "for item in progressbar.ProgressBar()(missing):\n",
    "    mime, ext = item[\"mimeType\"].split(\"/\")\n",
    "    filename = f\"{item['id']}.{ext}\"\n",
    "    if \"image\" in item:\n",
    "        with open(os.path.join(\"missing\", filename), \"wb\") as fp:\n",
    "            fp.write(item[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17050226287"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIST[0][\"hash\"].__hash__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17050226287182450803"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIST[0][\"hash\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (23451 of 23451) |##################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "for i, item in progressbar.ProgressBar(max_value=len(LIST))(enumerate(LIST)):\n",
    "    if item[\"productUrl\"] in batch:\n",
    "        del LIST[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (23061 of 23061) |##################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "for item in progressbar.ProgressBar()(LIST):\n",
    "    try:\n",
    "        item[\"hash\"] = Hash(item[\"hash\"].hash)\n",
    "    except (KeyError, OSError):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17050226287182450803"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIST[0][\"hash\"].__hash__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

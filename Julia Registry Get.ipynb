{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import textwrap\n",
    "import toml\n",
    "\n",
    "from multiprocessing.pool import Pool\n",
    "from typing import Tuple, Callable, Type, Any\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s:%(threadName)s:%(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to store package registry and the Git executable\n",
    "packages_path = 'K:\\\\julia_packages2'\n",
    "git = 'K:\\\\Git\\\\bin\\\\git.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the URL to the Julia default package registry and clone/fetch the latest registry\n",
    "reg_url = 'https://github.com/JuliaRegistries/General.git'\n",
    "reg_path = os.path.join(packages_path, 'General')\n",
    "if os.path.exists(reg_path):\n",
    "    subprocess.run([git, 'pull'], cwd=reg_path)\n",
    "else:\n",
    "    subprocess.run([git, 'clone', reg_url, reg_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the registry TOML file into a really big dictionary\n",
    "with open(os.path.join(reg_path, 'Registry.toml')) as infile:\n",
    "    registry_data = toml.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk through the TOML dictionary, grabbing the package names and their Git repo URLs\n",
    "pkg_download = {}\n",
    "for pkg in sorted(registry_data['packages'].values(), key=lambda x: x['name']):\n",
    "    with open(os.path.join(reg_path, pkg['path'], 'Package.toml')) as infile:\n",
    "        pkg_toml = toml.load(infile)\n",
    "    pkg_repo = pkg_toml['repo'].replace('git://', 'https://')\n",
    "    pkg_download[pkg_toml['name']] = pkg_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_mirror(pkg_repo: str, packages_path: str = packages_path,\n",
    "                 redo: bool = False) -> Tuple[str, int]:\n",
    "\n",
    "    \"\"\"Performs a mirror Git clone of a repository.\n",
    "    \n",
    "    Args:\n",
    "        pkg_repo: The URL of the Git repository to clone.\n",
    "        packages_path: The path to the local directory to clone into.\n",
    "        redo: If a clone exists, delete it and re-clone, otherwise do nothing.\n",
    "      \n",
    "    Returns:\n",
    "        pkg_repo: The input `pkg_repo` parameter.\n",
    "        ret: The return code from Git, or ``None`` if `redo` was ``False`` and\n",
    "            the clone existed.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    pkg_repo_base = os.path.basename(pkg_repo)\n",
    "    pkg_path = os.path.join(packages_path, pkg_repo_base)\n",
    "\n",
    "    ret = None\n",
    "    \n",
    "    if redo:\n",
    "        try:\n",
    "            shutil.rmtree(pkg_path)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "    \n",
    "    if not os.path.exists(pkg_path):\n",
    "        logging.info('Cloning %s from %s', pkg_repo_base, pkg_repo)\n",
    "        ret = subprocess.run([git, 'clone', '--mirror', pkg_repo, pkg_path]).returncode\n",
    "    \n",
    "    return pkg_repo, ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async loop over the package URLs, cloning each one and storing the return codes in a dictionary\n",
    "with Pool() as pool:\n",
    "    results = dict(pool.imap(clone_mirror, pkg_download.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the return codes. If a code was nonzero, try to clone again!\n",
    "for pkg_repo, ret in results.items():\n",
    "    if ret is not None and ret != 0:\n",
    "        clone_mirror(pkg_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(pkg_repo: str, packages_path: str = packages_path) -> Tuple[str, int]:\n",
    "\n",
    "    \"\"\"Performs a fetch in a local Git repository, whose location is\n",
    "    determined from the remote URL.\n",
    "    \n",
    "    Args:\n",
    "        pkg_repo: The URL of the remote Git repository.\n",
    "        packages_path: The path to the local directory where the clone is located.\n",
    "      \n",
    "    Returns:\n",
    "        pkg_repo: The input `pkg_repo` parameter.\n",
    "        ret: The return code from Git, or ``None`` if the clone doesn't exist.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    pkg_repo_base = os.path.basename(pkg_repo)\n",
    "    pkg_path = os.path.join(packages_path, pkg_repo_base)\n",
    "\n",
    "    ret = None\n",
    "    \n",
    "    if os.path.exists(pkg_path):\n",
    "        logging.info('Fetching in %s', pkg_path)\n",
    "        ret = subprocess.run([git, 'fetch'], cwd=pkg_path).returncode\n",
    "    \n",
    "    return pkg_repo, ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async loop over the package URLs, fetching on each one to ensure we have the latest and the clone is good\n",
    "with Pool() as pool:\n",
    "    results = dict(pool.imap(fetch, pkg_download.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the return codes. If a code was nonzero, try to fetch again!\n",
    "# Anything that fails at this point is either an invalid URL or we have bad creds!\n",
    "for pkg_repo, ret in results.items():\n",
    "    if ret is not None and ret != 0:\n",
    "        fetch(pkg_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onerror(func: Callable, path: str, exc_info: Tuple[Type, Exception, Any]):\n",
    "    \n",
    "    \"\"\"Error handler for ``shutil.rmtree``.\n",
    "\n",
    "    If the error is due to an access error (read only file)\n",
    "    it attempts to add write permission and then retries.\n",
    "\n",
    "    If the error is for another reason it re-raises the error.\n",
    "\n",
    "    Usage : ``shutil.rmtree(path, onerror=onerror)``\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    import stat\n",
    "    if not os.access(path, os.W_OK):\n",
    "        # Is the error an access error ?\n",
    "        os.chmod(path, stat.S_IWUSR)\n",
    "        func(path)\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Julia language repo needs to download some dependencies when it's built.\n",
    "# This is normally done using \"make -d deps getall\", but we don't have GNU make\n",
    "# on the IAS. So we have to walk the Makefiles ourselves and manuall download\n",
    "# the dependencies so we can ingress them, too!\n",
    "\n",
    "# Clone Julia from the bare repo\n",
    "julia_repo = os.path.join(packages_path, 'julia.git')\n",
    "julia_path = os.path.join(packages_path, 'julia')\n",
    "if os.path.exists(julia_path):\n",
    "    shutil.rmtree(julia_path, onerror=onerror)\n",
    "subprocess.run([git, 'clone', julia_repo, julia_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run GNU make to get the dependencies\n",
    "pwd = os.getcwd()\n",
    "os.chdir(os.path.join(julia_path, 'deps'))\n",
    "ret = os.system(f\"make getall\")\n",
    "os.chdir(pwd)\n",
    "if ret != 0:\n",
    "    raise RuntimeError(\"Getting Julia dependencies failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip up the directory to transfer to NNPP\n",
    "topdir = os.path.realpath(os.path.dirname(packages_path))\n",
    "subprocess.run(['tar', 'czf', 'julia_packages.tar.gz', 'julia_packages'], cwd=topdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
